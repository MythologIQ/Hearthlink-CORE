# Project Concept

## Why (One Sentence)

The Hearthlink CORE Runtime is a sandboxed, offline inference engine that performs model execution only and has no authority over data, tools, or system actions.

## Vibe (Three Keywords)

1. **Minimal** - Pure function: tokens in, tokens out. No scope creep.
2. **Secure** - Sandboxed, isolated, zero network access, least privilege.
3. **Traceable** - Deterministic execution with observable metrics, no hidden state.

## Anti-Goals (What This Is NOT)

- NOT an agent (no autonomous decision-making)
- NOT a plugin host (no external code execution)
- NOT a connector layer (no network access)
- NOT a policy engine (no governance authority)
- NOT a memory store (no persistent state)
- NOT an orchestrator (no workflow management)

## Design Pillars Alignment

| Pillar | How CORE Supports It |
|--------|---------------------|
| Data Sovereignty | No persistent storage or network - cannot leak data |
| System Integrity | Sandbox + isolation - cannot bypass boundaries |
| AI Governance | No authority - cannot act independently |
| System Reliability | Stateless + restartable - safe recovery |

---

## Performance Goals

### Measurable Objectives

| Goal | Metric | Validation Method |
|------|--------|-------------------|
| **Secure** | 50+ security tests passing | TDD-Light security validation suite |
| **Compute Efficient** | CPU-only, no GPU required | Benchmark on 4-8 core reference hardware |
| **Fast Inference** | Meet tier targets (see below) | Criterion benchmark suite |
| **Memory Efficient** | RSS ≤ 1.5x model file size | Memory overhead benchmarks |

### Tier Progression Targets

Performance targets account for "security tax" (40-88% overhead vs unsandboxed runtimes).

#### Tier 1: Minimum Viable (Baseline)

| Metric | Target | Rationale |
|--------|--------|-----------|
| Generation | >10 tok/s | Safe floor for Phi-3 Q4 on 4-core CPU |
| Classification P95 | <100ms | Generous for sandboxed ONNX |
| Memory Ratio | <1.5x | Industry standard ceiling |

**Proves**: Sandbox works without catastrophic overhead.

#### Tier 2: Competitive (Stretch)

| Metric | Target | vs Industry |
|--------|--------|-------------|
| Generation | >25 tok/s | ~30% of CPU Ollama (80 tok/s) |
| Classification P95 | <20ms | ~10x slower than bare ONNX (1.86ms) |
| Memory Ratio | <1.35x | Match llama.cpp baseline |

**Requires**: IPC optimization, memory-mapped loading, thread tuning, KV-cache optimization.

#### Tier 3: Optimized (Future)

| Metric | Target | vs Industry |
|--------|--------|-------------|
| Generation | >50 tok/s | ~60% of CPU Ollama |
| Classification P95 | <5ms | ~3x slower than bare ONNX |
| Memory Ratio | <1.25x | Aggressive memory pooling |

**Requires**: Custom allocator, SIMD tokenization, speculative decoding.

### External Reference Benchmarks

| Runtime | Hardware | Performance | Source |
|---------|----------|-------------|--------|
| llama.cpp | M2 Ultra | 109 tok/s (TG) | GitHub #4167 |
| Ollama | 16-core EPYC (CPU) | 80 tok/s | Medium benchmarks |
| vLLM | 16-core EPYC (CPU) | 55 tok/s | Medium benchmarks |
| ONNX Runtime | Azure Cobalt 100 | 1.86ms / 538 inf/s | Arm Learn |

### Security Tax Visualization

```
Unsandboxed Ollama CPU:  ████████████████████ 80 tok/s (100%)
Tier 3 Target:           ████████████         50 tok/s (62%)
Tier 2 Target:           ██████               25 tok/s (31%)
Tier 1 Target:           ███                  10 tok/s (12%)
```

The 40-88% performance reduction is the cost of:
- Process isolation (seccomp/AppContainer)
- IPC serialization overhead
- No shared memory with caller
- Constant-time security operations

---

_Generated by QoreLogic A.E.G.I.S. Bootstrap_
